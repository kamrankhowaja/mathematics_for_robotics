{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1eb20dcf-9936-4a85-b45b-beba0a0361c3",
   "metadata": {},
   "source": [
    "# Bayes Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1362ff-b9ed-4946-8d98-934188046097",
   "metadata": {},
   "source": [
    "### Prerequiste:\n",
    "\n",
    "You should know about \n",
    "- Kolmogorov's Axioms\n",
    "- Conditional Probability\n",
    "- Conditional Independence & Dependence "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c65113-53e6-41e2-ba88-91f3fa619b61",
   "metadata": {},
   "source": [
    "**Key Terms**\n",
    "\n",
    "- **Joint Probability :** is statistical measure where the likelihood of two events occurring together and at the same point in time are calculated. Because joint probability is the probability of two events occurring at the same time, it can only be applied to situations where more than one observation can be made at the same time.\n",
    "- **Conditional Probability :** is the probability of one event occurring, given that another event occurs.\n",
    "- **Marginal Probability :** is the unconditional probability of one event; in other words, the probability of an event, regardless of whether another event occurs or not. Finding the marginal probability of an event involves summing all possible configurations of the other event to obtain a weighted average probability.\n",
    "- **Independent Events :** If the two events are considered independent, each can occur individually and the outcome of one event does not affect the outcome of the other event in any way.\n",
    "- **Dependent Events :** If the two events are considered dependent, then the outcome of the second event depends on the probability of the first event. The probabilities of the individual events must be analyzed with conditional probability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83921980-4d3a-4724-96aa-79385d278cc0",
   "metadata": {},
   "source": [
    "**Bayes Theorem** \n",
    "\n",
    "Bayes theorem allows merging of multiple evidence into a single(more consolidated) view of the world"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961b3fe2-1b2d-458f-b34c-7c0c02bf87ee",
   "metadata": {},
   "source": [
    "### Two World \n",
    "\n",
    "Assume you have two dice. $D_1 = {1,2,3,4,5,6}$ with $P(D_{1i}) = \\frac{1}{6}$, Das ist Fair Dice \n",
    "\n",
    "Another unfair dice $D_2 = {1,2,3,4,5,6}$ with $P(D_{2i}) = \\{ 0.15,0.05,0.3,0.3,0.05,0.15 \\}$ \n",
    "\n",
    "you randomly observe a sequence 3 und dann 1 und dann 2. so what's the probability that the observed numbers are from Dice A or Dice B\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6c1d44-3d5b-462f-8cd7-e473d14eb2f0",
   "metadata": {},
   "source": [
    "**First Observation**\n",
    "\n",
    "Probability of $3$ in $P(3) = P(3|A)P(A) + P(3|B)P(B) = \\frac{1}{6}.\\frac{1}{2} + 0.3.\\frac{1}{2} = \\frac{7}{30}$\n",
    "\n",
    "Probability of $3$ in World $A$ : $P(A|3) = \\frac{P(3|A) P(A)}{P(3)} = \\frac{\\frac{1}{6}.\\frac{1}{2}}{\\frac{7}{30}} = \\frac{5}{14}$\n",
    "\n",
    "Probability of $3$ in World $B$ : $P(B|3) = \\frac{P(3|B) P(B)}{P(3)} = \\frac{0.3.\\frac{1}{2}}{\\frac{7}{30}} = \\frac{9}{14}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9810df-d2b0-405b-9b99-3c6288cefce3",
   "metadata": {},
   "source": [
    "**Second Observation**\n",
    "\n",
    "Probability of $1$ given that you have seen $3$ in $P(1) = P(1|A)P(A,3) + P(1|B)P(B,3) = \\frac{1}{6}.\\frac{5}{14} + 0.15.\\frac{9}{14} = \\frac{131}{840}$\n",
    "\n",
    "Probability of $1$ in World $A$ : $P(A|1, 3) = \\frac{P(1|A) P(A,3)}{P(1)} = \\frac{\\frac{1}{6}.\\frac{5}{14}}{\\frac{131}{840}} = \\frac{50}{13}$\n",
    "\n",
    "Probability of $1$ in World $B$ : $P(B|1, 3) = \\frac{P(1|B) P(B,3)}{P(1)} = \\frac{0.15.\\frac{9}{14}}{\\frac{131}{840}} = \\frac{81}{131}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5edae33-3066-485a-89e2-73d6e214edd7",
   "metadata": {},
   "source": [
    "**Third Observation**\n",
    "\n",
    "Probability of $2$ given that you have seen $1,3$ in $P(2) = P(2|A)P(A,1|3) + P(2|B)P(B,1|3) = \\frac{1}{6}.\\frac{50}{13} + 0.05.\\frac{81}{131} = \\frac{743}{7860}$\n",
    "\n",
    "Probability of $2$ in World $A$ : $P(A|2, 1|3) = \\frac{P(2|A)P(A,1|3)}{P(2)} = \\frac{\\frac{1}{6}.\\frac{50}{13}}{\\frac{743}{7860}} = \\frac{500}{743}$\n",
    "\n",
    "Probability of $2$ in World $B$ : $P(B|2, 1|3) = \\frac{P(2|B)P(B,1|3)}{P(2)} = \\frac{0.05.\\frac{81}{131}}{\\frac{743}{7860}} = \\frac{243}{743}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788f72c8-cffe-480a-86d9-a162430016ab",
   "metadata": {},
   "source": [
    "## LUCY World "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255ba88c-795b-44be-b681-4d0c2b0bd65d",
   "metadata": {},
   "source": [
    "Lucy, the robot, has a low-range sensor to detect the state of doors (open / closed). In the building that Lucy operates in, $80%$ of the doors are closed on average.Lucy‘s sensor is cheap but relies on a good calibration. If it is calibrated well, the probability of correctly detecting a door state is $90%$,however, the slightest miscalibration leads to a drop to $60%$.\n",
    "\n",
    "Unfortunately, Lucy bumped into a bunch of students yesterday and now the sensor might be miscalibrated.\n",
    "\n",
    "Lucy has operated all morning and found the following door states (for different doors in the building):\n",
    "**Open, open, closed, open, closed, closed, closed, closed, open, closed, closed, closed, open, open, closed, closed, closed, closed**\n",
    "\n",
    "- What is the probaility that Lucy‘s sensor is miscalibrated?\n",
    "- How does Lucy‘s belief change with each new door state?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98005ad1-90da-47d8-aaa1-a9b8d744416d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = Image.open('img/lucy.png')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ae505d-914b-4857-b001-1ae65a54920f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('img/lucysolve.png')\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd26eb2-70f8-4564-a48b-597510ec953f",
   "metadata": {},
   "source": [
    "### Bayesian Decision Theory\n",
    "\n",
    "1. **Priors:** What can we about the occcurence before of an event, if we have not seen its current state (Waht does your Previous knowlegde tells your about)\n",
    "2. **Conditional Probabilities:** let x be a feature of any input. where x describes the plausibility(likelihood) of Class C. it is given as $P(A|B) = \\frac{P(A \\cap B)}{P(B)}$\n",
    "3. **Posterior Probability:** we are typically interested in this, as we need to find occuence of an event after having an event x observation. it is given by $P(C_k | x) = \\frac{P(x| C_k).P(C_k)}{P(x)}$\n",
    "\n",
    "\n",
    "**Deductive logic:** deriving consequences from the cause, As in pure mathematics: useful conclusions as logical consequence of a few well-defined axioms.\n",
    "\n",
    "**Inductive logic:** deriving possible causes from the observed consequences/effect , if the effects are observed, deduce the possible/plausible cause"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2347fe8c-d7ea-44b9-a259-612d1ab57ef3",
   "metadata": {},
   "source": [
    "### Activity Time\n",
    "\n",
    "Take a coin with the events: HEAD == H == 1 and TAILS == T == 0.\n",
    "\n",
    "This coin produces HEAD with a probability of $p$. Here $p$ is a number with $0 < p < 1$\n",
    "\n",
    "Suppose we observed exactly one Bernoulli chain: length: 14\n",
    "- 10 times '1' ,\n",
    "- 4 times '0‘\n",
    "- z. B (0,1,1,1,1,1,0,1,0,1,1,1,0,1).\n",
    "\n",
    "**With this data, would you bet on the event that the next two tosses of THIS coin will be (1,1) or better not?**\n",
    "\n",
    "Calculate the probabilities in two ways:\n",
    "- in a frequency-based manner.\n",
    "- according to the theorem of Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3e6efb-9563-4a45-ab26-86f9a6a4740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency Based Manner \n",
    "print(\"Frequency Based Manner Approach\")\n",
    "my_data = [0,1,1,1,1,1,0,1,0,1,1,1,0,1]\n",
    "\n",
    "MyH = my_data.count(1)\n",
    "MyT = my_data.count(0)\n",
    "\n",
    "PFreq_H = MyH / len(my_data)\n",
    "\n",
    "two_head_HH = PFreq_H * PFreq_H\n",
    "\n",
    "print(\"Probability that next two are head (H,H) is {}\".format(two_head_HH))\n",
    "print(\"In a frequentistic world, it would therefore pay off to bet on two (1,1) in a row in the long run.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f7c32f-efb0-4acb-b275-35b176f721f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# The Bayesian Way \n",
    "print(\"The Bayesian Way (Beta Distribution)\")\n",
    "outcomes = [0,1,1,1,1,1,0,1,0,1,1,1,0,1]\n",
    "\n",
    "print(\"Using Beta Distribution Method , as you don't know prior probabilities you consider that the next could be head order tail\")\n",
    "\n",
    "Beta_val = [11,5] # one for head and one for tail \n",
    "#Head_head = prob**2\n",
    "\n",
    "#Now Finding the Expected Value of prob\n",
    "\n",
    "EX_Prob = ((Beta_val[0])*(Beta_val[0]+1))/((Beta_val[0]+Beta_val[1])*(Beta_val[0]+Beta_val[1] +1))\n",
    "\n",
    "print(\"The probability of getting straight HH is {}\".format(EX_Prob))\n",
    "print(f\"As {EX_Prob} is too low, its seems that chances are low\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
